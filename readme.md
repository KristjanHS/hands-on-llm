# ðŸš€ My Hands-On LLM Learning Journey

This repository tracks my hands-on learning journey with Local Large Language Models (LLMs), focusing on practical implementation and experimentation. Each phase builds upon the previous one, creating a comprehensive understanding of LLM development from environment setup to advanced applications.

## ðŸ§­ Phases

### âœ… [Phase 0](./phase0/)
> *Goal:* Set up robust development environment (WSL2 + Python + CUDA + PyTorch GPU)
- Complete WSL2 configuration with GPU support
- Python 3.11 environment setup
- CUDA toolkit and PyTorch integration
- Jupyter notebook configuration
- Basic GPU validation tests

### âœ… [Phase 1](./phase1/)
> *Goal:* Local LLM experimentation and integration
- Local model deployment (Ollama, etc.)
- API integration and benchmarking
- Multiple model architectures
- Performance analysis and optimization
- Interactive notebooks and examples

### ðŸ”œ Future Phases
> Planning in progress...

## ðŸ›  Key Features

- **WSL2 + GPU Integration**: Optimized for Windows development with Linux tools
- **Local LLM Focus**: Run and experiment with models on your own hardware
- **Comprehensive Documentation**: Clear setup instructions and examples
- **Performance Analysis**: Benchmarking and optimization tools
- **Interactive Learning**: Jupyter notebooks for hands-on experimentation

## ðŸ“Œ Why This Exists

This repository serves as both a learning journal and a practical reference for LLM development. It demonstrates:
- Setting up a robust development environment
- Working with local LLM deployments
- Understanding model behavior and performance
- Practical implementation patterns and best practices

The goal is to provide a clear path from initial setup to advanced LLM applications, with each phase building upon previous knowledge.M Learning Journey

This repository tracks my hands-on learning with Python, GitHub, WSL, and Large Language Models (LLMs). Each phase is a self-contained learning project.

## ðŸ§­ Phases

### âœ… [Phase 0](./phase0/)
> *Goal:* Set up environment (WSL + Python + PyTorch GPU) and validate setup.

### ðŸ”œ Phase 1: Prompt Engineering
> *Goal:* Learn prompt design, tokenization, temperature, and logit bias in OpenAI/transformer models.

(â€¦and more to come)

---

## ðŸ“Œ Why This Exists

Iâ€™m using this repo to document and demonstrate my growth, hands-on experiments, and working knowledge in applied AI development â€” from the system layer to LLM interaction techniques.
